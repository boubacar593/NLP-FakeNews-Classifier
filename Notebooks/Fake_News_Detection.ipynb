{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# local\n",
        "!pip install pandas numpy scikit-learn joblib\n",
        "\n",
        "# optionnel pour BERT\n",
        "!pip install transformers datasets accelerate evaluate tokenizers\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "82w1chBvStZG",
        "outputId": "9ff3e082-08a5-4edf-837e-848c9098ce2d"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (1.5.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.2)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.12/dist-packages (4.0.0)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.12/dist-packages (1.12.0)\n",
            "Collecting evaluate\n",
            "  Downloading evaluate-0.4.6-py3-none-any.whl.metadata (9.5 kB)\n",
            "Requirement already satisfied: tokenizers in /usr/local/lib/python3.12/dist-packages (0.22.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.20.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.36.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2025.11.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.7.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets) (3.6.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2025.3.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from accelerate) (2.9.0+cu126)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.13.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.2.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2025.11.12)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.5.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.22.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.3)\n",
            "Downloading evaluate-0.4.6-py3-none-any.whl (84 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: evaluate\n",
            "Successfully installed evaluate-0.4.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kr5Q7-QzdWa2",
        "outputId": "125016a4-7eb2-43a3-d60f-c87fcaef187c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "    import pandas as pd\n",
        "    import numpy as np\n",
        "    import matplotlib.pyplot as plt\n",
        "    import seaborn as sns\n",
        "    import os\n",
        "    import random\n",
        "    import re\n",
        "    import string\n",
        "    from sklearn.model_selection import train_test_split\n",
        "    from sklearn.metrics import accuracy_score\n",
        "    from sklearn.metrics import confusion_matrix\n",
        "    from sklearn.metrics import classification_report\n",
        "    import sklearn.ensemble as ensemble\n",
        ""
      ],
      "metadata": {
        "id": "Q1P6DHVjHZ8E"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_fake = pd.read_csv('/content/drive/MyDrive/Data/Fake.csv')\n",
        "df_true = pd.read_csv('/content/drive/MyDrive/Data/True.csv')"
      ],
      "metadata": {
        "id": "OouemK5XIjqj"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CHARGEMENT ET CONCATENATION DES DONNEES"
      ],
      "metadata": {
        "id": "v-VWlGgvTrML"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "df_fake = pd.read_csv('/content/drive/MyDrive/Data/Fake.csv')\n",
        "df_true = pd.read_csv('/content/drive/MyDrive/Data/True.csv')\n",
        "\n",
        "df_fake['label'] = 0\n",
        "df_true['label'] = 1\n",
        "\n",
        "# s'assurer que title/text existent\n",
        "for col in ['title','text','subject','date']:\n",
        "    if col not in df_fake.columns: df_fake[col] = \"\"\n",
        "    if col not in df_true.columns: df_true[col] = \"\"\n",
        "\n",
        "df = pd.concat([df_fake, df_true], ignore_index=True)\n",
        "df = shuffle(df, random_state=42).reset_index(drop=True)\n",
        "\n",
        "print(\"Total rows:\", df.shape[0])\n",
        "print(df['label'].value_counts())\n",
        "df.head()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "id": "hkCwMxy9Naed",
        "outputId": "c76d59f8-59ed-427d-fe33-9b8f4f602dae"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total rows: 44898\n",
            "label\n",
            "0    23481\n",
            "1    21417\n",
            "Name: count, dtype: int64\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               title  \\\n",
              "0  Ben Stein Calls Out 9th Circuit Court: Committ...   \n",
              "1  Trump drops Steve Bannon from National Securit...   \n",
              "2  Puerto Rico expects U.S. to lift Jones Act shi...   \n",
              "3   OOPS: Trump Just Accidentally Confirmed He Le...   \n",
              "4  Donald Trump heads for Scotland to reopen a go...   \n",
              "\n",
              "                                                text       subject  \\\n",
              "0  21st Century Wire says Ben Stein, reputable pr...       US_News   \n",
              "1  WASHINGTON (Reuters) - U.S. President Donald T...  politicsNews   \n",
              "2  (Reuters) - Puerto Rico Governor Ricardo Rosse...  politicsNews   \n",
              "3  On Monday, Donald Trump once again embarrassed...          News   \n",
              "4  GLASGOW, Scotland (Reuters) - Most U.S. presid...  politicsNews   \n",
              "\n",
              "                  date  label  \n",
              "0    February 13, 2017      0  \n",
              "1       April 5, 2017       1  \n",
              "2  September 27, 2017       1  \n",
              "3         May 22, 2017      0  \n",
              "4       June 24, 2016       1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d39d2f7d-df4a-4eea-85af-19a316cdd553\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>text</th>\n",
              "      <th>subject</th>\n",
              "      <th>date</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Ben Stein Calls Out 9th Circuit Court: Committ...</td>\n",
              "      <td>21st Century Wire says Ben Stein, reputable pr...</td>\n",
              "      <td>US_News</td>\n",
              "      <td>February 13, 2017</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Trump drops Steve Bannon from National Securit...</td>\n",
              "      <td>WASHINGTON (Reuters) - U.S. President Donald T...</td>\n",
              "      <td>politicsNews</td>\n",
              "      <td>April 5, 2017</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Puerto Rico expects U.S. to lift Jones Act shi...</td>\n",
              "      <td>(Reuters) - Puerto Rico Governor Ricardo Rosse...</td>\n",
              "      <td>politicsNews</td>\n",
              "      <td>September 27, 2017</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>OOPS: Trump Just Accidentally Confirmed He Le...</td>\n",
              "      <td>On Monday, Donald Trump once again embarrassed...</td>\n",
              "      <td>News</td>\n",
              "      <td>May 22, 2017</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Donald Trump heads for Scotland to reopen a go...</td>\n",
              "      <td>GLASGOW, Scotland (Reuters) - Most U.S. presid...</td>\n",
              "      <td>politicsNews</td>\n",
              "      <td>June 24, 2016</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d39d2f7d-df4a-4eea-85af-19a316cdd553')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d39d2f7d-df4a-4eea-85af-19a316cdd553 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d39d2f7d-df4a-4eea-85af-19a316cdd553');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-f849c78f-3393-4446-8197-23b637c4a2c2\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f849c78f-3393-4446-8197-23b637c4a2c2')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-f849c78f-3393-4446-8197-23b637c4a2c2 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 44898,\n  \"fields\": [\n    {\n      \"column\": \"title\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 38729,\n        \"samples\": [\n          \" WATCH: Dem Senator BLASTS Trump, Calls Him A Liar Live On Air\",\n          \"Trump calls for firm response to North Korea, targets Seoul on trade\",\n          \"Zimbabwe army leaves streets a month after Mugabe's ouster\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 38646,\n        \"samples\": [\n          \"It takes one to know one. Turkey just held a referendum that greatly expands the power of their president, Recep Tayyip Erdogan. It passed by a very narrow margin, taking Turkey on its latest step toward brutal dictatorship, and here s Donald Trump, who sources say called Erdogan to congratulate him on  winning  the referendum vote.While we re busy justifying blowing up absolutely nothing in Syria because a brutal dictator used sarin gas on his people, Trump is busy calling someone who s working hard on becoming the region s next brutal dictator to congratulate him on furthering that goal.This referendum, according to The Daily Beast, moves Turkey away from a parliamentary democracy and towards one-person rule. But what he has already done there makes the referendum more of a formality. Erdogan had already managed to form a one-party government   a move that greatly diminishes the voices of opposition.Last year, Erdogan asked Turkey s parliament to redefine the country s anti-extremism law to include politicians, journalists and members of academia. He claimed that  pro-Kurdish  politicians were inciting terrorism, and journalists and academics were spreading the info that allowed the politicians to do so. Therefore, they are all terrorists.Branding press as  the enemy  is something Trump has been trying to do here. As the Washington Post s front page motto says,  Democracy dies in darkness.  This is the darkness.And now, Erdogan is, more or less, the sole ruler of Turkey.But what does Trump care? It wouldn t be surprising to find that he wishes something like that would happen here, too, if for no other reason than it would help cement his overinflated opinion of himself as a great man who is beloved by all, with nobody left to shine a light on the truth, like, oh, say, a free press.The way the Turkey referendum was held has appalled international election monitors. According to them,  voters were not provided with adequate information, opposition voices were muzzled and the rules were changed at the last minute.  In short, this was not a truly democratic process.Good job continuing to support authoritarian rulers over true democracies, Trump. You re about as un-American as it gets.Featured image by Mark Wilson via Getty Images\",\n          \"Donald Trump just got caught lying again and there is video to prove it.When former FBI Director James Comey testified under oath in the Senate on Thursday, he recalled that Trump demanded loyalty from him before he was asked to drop the investigation of Michael Flynn and Trump s ties to Russia. The President said,  I need loyalty, I expect loyalty,  Comey testified.But when asked by ABC reporter Jon Karl if he had demanded Comey s loyalty, Trump denied the whole thing and pretended that he has never demanded loyalty from anyone in his entire life. So he said those things under oath,  Karl began.  Would you be willing to speak under oath to give your version of those events? One hundred percent,  Trump replied.  I didn t say under oath   I hardly know the man. I m not going to say, I want you to pledge allegiance. Who would do that? Who would ask a man to pledge allegiance under oath? I mean, think of it. I hardly know the man. It doesn t make sense. No, I didn t say that, and I didn t say the other. If Trump were to say this under oath he would he would be committing perjury. And CNN proved it by playing video of Trump on the campaign trail in Florida asking people in the crowd to raise their hands and pledge their loyalty to him. Keep in mind that Trump had never met anyone in that audience. But he had several discussions and meetings with Comey. In other words, Comey was not a complete stranger to him. If he was willing to ask a crowd of random people to pledge their allegiance to him, he would certainly be willing to demand loyalty from Comey.Here s the damning video via YouTube.This is yet more proof that Trump is a liar who has zero credibility. He will say anything to save his own ass.Featured image via Olivier Douliery   Pool/Getty Images\",\n          \"WASHINGTON (Reuters) - The U.S. State Department said on Monday Washington was  very concerned  by reports of violence around the Iraqi oil city of Kirkuk, which was seized by Baghdad s forces from Kurds.  We are monitoring the situation closely and call on all parties to coordinate military activities and restore calm,   State Department spokeswoman Heather Nauert said in a statement. \"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"subject\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 8,\n        \"samples\": [\n          \"politicsNews\",\n          \"worldnews\",\n          \"US_News\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"date\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2397,\n        \"samples\": [\n          \"July 3, 2016\",\n          \"Jul 29, 2015\",\n          \"Nov 28, 2016\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ANALYSE EXPLORATOIRE DES DONNEES"
      ],
      "metadata": {
        "id": "2rK55ESpT7Oy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# distributions et stats simples\n",
        "df['content'] = df['title'].fillna('') + \" \" + df['text'].fillna('')\n",
        "df['n_words'] = df['content'].apply(lambda t: len(str(t).split()))\n",
        "print(df['n_words'].describe())\n",
        "\n",
        "# ex : afficher les 5 titres les plus longs\n",
        "df.loc[df['n_words'].nlargest(5).index, ['title','n_words']]\n",
        "\n",
        "# distribution label\n",
        "print(df['label'].value_counts(normalize=True))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u0WsA1-ATUY0",
        "outputId": "91842d58-7c20-4f59-cbaf-f2448e03ab88"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "count    44898.000000\n",
            "mean       417.735757\n",
            "std        351.480777\n",
            "min          2.000000\n",
            "25%        216.000000\n",
            "50%        375.000000\n",
            "75%        526.000000\n",
            "max       8148.000000\n",
            "Name: n_words, dtype: float64\n",
            "label\n",
            "0    0.522985\n",
            "1    0.477015\n",
            "Name: proportion, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# NETTOYAGE ET PRETRAITEMENT"
      ],
      "metadata": {
        "id": "ncbgzJICUQ5w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re, string\n",
        "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
        "\n",
        "STOPWORDS = set(ENGLISH_STOP_WORDS)\n",
        "\n",
        "def clean_text(text):\n",
        "    if not isinstance(text, str):\n",
        "        return \"\"\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'http\\S+|www\\.\\S+', ' ', text)          # URLs\n",
        "    text = re.sub(r'<.*?>', ' ', text)                     # HTML mini\n",
        "    text = text.translate(str.maketrans('', '', string.punctuation))  # punctuation\n",
        "    text = re.sub(r'\\d+', ' ', text)                       # chiffres\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()               # espaces\n",
        "    tokens = [w for w in text.split() if w not in STOPWORDS and len(w) > 1]\n",
        "    return \" \".join(tokens)\n",
        "\n",
        "df['clean'] = df['content'].apply(clean_text)\n"
      ],
      "metadata": {
        "id": "s_bXfu1NT2Nq"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DIVISER LE DATASET CONCATENER EN DONNEES D' ENTRAINEMENT ET DE TEST"
      ],
      "metadata": {
        "id": "1UvSL-QlUa16"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X = df['clean'].values\n",
        "y = df['label'].values\n",
        "\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.25, stratify=y, random_state=42)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, stratify=y_temp, random_state=42)\n",
        "\n",
        "print(\"Train:\", len(X_train), \"Val:\", len(X_val), \"Test:\", len(X_test))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yngbLoRRUKvs",
        "outputId": "6c4631bb-68ef-4b75-8cf3-06001bbe1591"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: 33673 Val: 5612 Test: 5613\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  ENTRAINEMENT"
      ],
      "metadata": {
        "id": "ramV7u8pUxpE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Définition des modèles à tester"
      ],
      "metadata": {
        "id": "_cJCwiGzWTNU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import f1_score, classification_report\n",
        "import numpy as np\n",
        "import joblib\n",
        "\n",
        "experiments = []\n",
        "\n",
        "# TF-IDF — Logistic Regression\n",
        "experiments.append((\n",
        "    \"TFIDF + Logistic Regression\",\n",
        "    Pipeline([\n",
        "        ('tfidf', TfidfVectorizer(max_df=0.95, min_df=4, ngram_range=(1,2))),\n",
        "        ('clf', LogisticRegression(max_iter=400, class_weight='balanced'))\n",
        "    ])\n",
        "))\n",
        "\n",
        "# TF-IDF — SVM\n",
        "experiments.append((\n",
        "    \"TFIDF + Linear SVM\",\n",
        "    Pipeline([\n",
        "        ('tfidf', TfidfVectorizer(max_df=0.95, min_df=4, ngram_range=(1,2))),\n",
        "        ('clf', LinearSVC())\n",
        "    ])\n",
        "))\n",
        "\n",
        "# TF-IDF — Naive Bayes\n",
        "experiments.append((\n",
        "    \"TFIDF + MultinomialNB\",\n",
        "    Pipeline([\n",
        "        ('tfidf', TfidfVectorizer(max_df=0.95, min_df=5)),\n",
        "        ('clf', MultinomialNB())\n",
        "    ])\n",
        "))\n",
        "\n",
        "# CountVectorizer — Logistic Regression\n",
        "experiments.append((\n",
        "    \"CountVectorizer + Logistic Regression\",\n",
        "    Pipeline([\n",
        "        ('count', CountVectorizer(min_df=4)),\n",
        "        ('clf', LogisticRegression(max_iter=400))\n",
        "    ])\n",
        "))\n",
        "\n",
        "# CountVectorizer — Linear SVM\n",
        "experiments.append((\n",
        "    \"CountVectorizer + Linear SVM\",\n",
        "    Pipeline([\n",
        "        ('count', CountVectorizer(min_df=4)),\n",
        "        ('clf', LinearSVC())\n",
        "    ])\n",
        "))\n",
        "\n",
        "# TF-IDF — RandomForest\n",
        "experiments.append((\n",
        "    \"TFIDF + RandomForest\",\n",
        "    Pipeline([\n",
        "        ('tfidf', TfidfVectorizer(min_df=5)),\n",
        "        ('clf', RandomForestClassifier(n_estimators=250))\n",
        "    ])\n",
        "))\n"
      ],
      "metadata": {
        "id": "stNRf9luUwKy"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gensim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DkdUg26sV__N",
        "outputId": "9b5ad214-0d83-4468-b935-ea1c44e2944e"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gensim\n",
            "  Downloading gensim-4.4.0-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (8.4 kB)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.12/dist-packages (from gensim) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from gensim) (1.16.3)\n",
            "Requirement already satisfied: smart_open>=1.8.1 in /usr/local/lib/python3.12/dist-packages (from gensim) (7.5.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from smart_open>=1.8.1->gensim) (2.0.1)\n",
            "Downloading gensim-4.4.0-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (27.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.9/27.9 MB\u001b[0m \u001b[31m47.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: gensim\n",
            "Successfully installed gensim-4.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Construction du vecteur Word2Vec"
      ],
      "metadata": {
        "id": "kCaU_HAoWeay"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import Word2Vec\n",
        "\n",
        "# préparer les tokens\n",
        "tokenized = [text.split() for text in X_train]\n",
        "\n",
        "# entraîner un Word2Vec rapide\n",
        "w2v_model = Word2Vec(sentences=tokenized, vector_size=100, window=5, min_count=3, workers=4)\n",
        "\n",
        "def embed_text(text):\n",
        "    words = [w for w in text.split() if w in w2v_model.wv]\n",
        "    if len(words) == 0:\n",
        "        return np.zeros(100)\n",
        "    return np.mean(w2v_model.wv[words], axis=0)\n",
        "\n",
        "# vectoriser datasets\n",
        "X_train_w2v = np.array([embed_text(t) for t in X_train])\n",
        "X_val_w2v   = np.array([embed_text(t) for t in X_val])\n",
        "X_test_w2v  = np.array([embed_text(t) for t in X_test])\n"
      ],
      "metadata": {
        "id": "is5jr-88V3OZ"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Ajouter Word2Vec + ML à la liste des modèles"
      ],
      "metadata": {
        "id": "L6C7_BcEb0Jk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "experiments.append((\n",
        "    \"Word2Vec + Logistic Regression\",\n",
        "    LogisticRegression(max_iter=400)\n",
        "))\n",
        "\n",
        "experiments.append((\n",
        "    \"Word2Vec + RandomForest\",\n",
        "    RandomForestClassifier(n_estimators=300)\n",
        "))\n"
      ],
      "metadata": {
        "id": "9sBL7NbKV9U3"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Boucle d’entraînement globale"
      ],
      "metadata": {
        "id": "YLZNEh03bwoJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results = []\n",
        "best_f1 = 0\n",
        "best_model = None\n",
        "best_name = \"\"\n",
        "\n",
        "for name, model in experiments:\n",
        "    print(\"\\n==============================\")\n",
        "    print(\"Training:\", name)\n",
        "    print(\"==============================\")\n",
        "\n",
        "    # cas Word2Vec (données numériques)\n",
        "    if \"Word2Vec\" in name:\n",
        "        model.fit(X_train_w2v, y_train)\n",
        "        y_pred = model.predict(X_val_w2v)\n",
        "    else:\n",
        "        model.fit(X_train, y_train)\n",
        "        y_pred = model.predict(X_val)\n",
        "\n",
        "    f1 = f1_score(y_val, y_pred)\n",
        "    print(\"F1-score:\", f1)\n",
        "    results.append((name, f1))\n",
        "\n",
        "    if f1 > best_f1:\n",
        "        best_f1 = f1\n",
        "        best_model = model\n",
        "        best_name = name\n",
        "\n",
        "print(\"\\n\\n=== Résultats finaux ===\")\n",
        "for name, f1 in results:\n",
        "    print(name, \"=> F1 =\", f1)\n",
        "\n",
        "print(\"\\nMeilleur modèle :\", best_name, \" avec F1 =\", best_f1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mT9qs9iNWkYd",
        "outputId": "838da972-23e2-4cad-d42c-7499d5b677de"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==============================\n",
            "Training: TFIDF + Logistic Regression\n",
            "==============================\n",
            "F1-score: 0.9892153216809223\n",
            "\n",
            "==============================\n",
            "Training: TFIDF + Linear SVM\n",
            "==============================\n",
            "F1-score: 0.9966430436404327\n",
            "\n",
            "==============================\n",
            "Training: TFIDF + MultinomialNB\n",
            "==============================\n",
            "F1-score: 0.9429049655941975\n",
            "\n",
            "==============================\n",
            "Training: CountVectorizer + Logistic Regression\n",
            "==============================\n",
            "F1-score: 0.997195737521032\n",
            "\n",
            "==============================\n",
            "Training: CountVectorizer + Linear SVM\n",
            "==============================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/svm/_base.py:1249: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1-score: 0.996258885147774\n",
            "\n",
            "==============================\n",
            "Training: TFIDF + RandomForest\n",
            "==============================\n",
            "F1-score: 0.9968277663743236\n",
            "\n",
            "==============================\n",
            "Training: Word2Vec + Logistic Regression\n",
            "==============================\n",
            "F1-score: 0.9808585764727745\n",
            "\n",
            "==============================\n",
            "Training: Word2Vec + RandomForest\n",
            "==============================\n",
            "F1-score: 0.9746741154562384\n",
            "\n",
            "\n",
            "=== Résultats finaux ===\n",
            "TFIDF + Logistic Regression => F1 = 0.9892153216809223\n",
            "TFIDF + Linear SVM => F1 = 0.9966430436404327\n",
            "TFIDF + MultinomialNB => F1 = 0.9429049655941975\n",
            "CountVectorizer + Logistic Regression => F1 = 0.997195737521032\n",
            "CountVectorizer + Linear SVM => F1 = 0.996258885147774\n",
            "TFIDF + RandomForest => F1 = 0.9968277663743236\n",
            "Word2Vec + Logistic Regression => F1 = 0.9808585764727745\n",
            "Word2Vec + RandomForest => F1 = 0.9746741154562384\n",
            "\n",
            "Meilleur modèle : CountVectorizer + Logistic Regression  avec F1 = 0.997195737521032\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WlkteztKbfx4",
        "outputId": "35cfa572-d55c-48bd-eeae-79502099ee3b"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.12/dist-packages (2.19.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (25.9.23)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from tensorflow) (25.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (5.29.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.32.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.2.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (4.15.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.0.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.76.0)\n",
            "Requirement already satisfied: tensorboard~=2.19.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.19.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.10.0)\n",
            "Requirement already satisfied: numpy<2.2.0,>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.0.2)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.15.1)\n",
            "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.5.4)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (0.1.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (0.18.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.11.12)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (3.0.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
        "\n",
        "max_words = 20000\n",
        "max_len = 300\n",
        "\n",
        "tokenizer = Tokenizer(num_words=max_words)\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "\n",
        "X_train_seq = pad_sequences(tokenizer.texts_to_sequences(X_train), maxlen=max_len)\n",
        "X_val_seq   = pad_sequences(tokenizer.texts_to_sequences(X_val), maxlen=max_len)\n",
        "\n",
        "model_lstm = Sequential([\n",
        "    Embedding(max_words, 128, input_length=max_len),\n",
        "    LSTM(128, return_sequences=False),\n",
        "    Dropout(0.3),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model_lstm.compile(\n",
        "    loss='binary_crossentropy',\n",
        "    optimizer='adam',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "history = model_lstm.fit(\n",
        "    X_train_seq, y_train,\n",
        "    validation_data=(X_val_seq, y_val),\n",
        "    epochs=3,\n",
        "    batch_size=128\n",
        ")\n",
        "\n",
        "# prédiction\n",
        "y_pred_lstm = (model_lstm.predict(X_val_seq) > 0.5).astype(int)\n",
        "f1_lstm = f1_score(y_val, y_pred_lstm)\n",
        "print(\"LSTM F1 =\", f1_lstm)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8pM0GafUWouq",
        "outputId": "3b6244d6-4a4c-42c9-956d-6eb5e3c4990f"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 32ms/step - accuracy: 0.9139 - loss: 0.2347 - val_accuracy: 0.9847 - val_loss: 0.0553\n",
            "Epoch 2/3\n",
            "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.9859 - loss: 0.0467 - val_accuracy: 0.9824 - val_loss: 0.0512\n",
            "Epoch 3/3\n",
            "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9943 - loss: 0.0210 - val_accuracy: 0.9852 - val_loss: 0.0554\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step\n",
            "LSTM F1 = 0.984626782737544\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "joblib.dump(best_model, \"best_fake_news_model.joblib\")\n",
        "print(\"Modèle sauvegardé :\", best_name)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fqSPKONCboZS",
        "outputId": "2ebae647-5e4d-4923-e6c3-d97bf2115ea6"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Modèle sauvegardé : CountVectorizer + Logistic Regression\n"
          ]
        }
      ]
    }
  ]
}